%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CS671: Machine Learning
% Copyright 2015 Pejman Ghorbanzade <mail@ghorbanzade.com>
% Creative Commons Attribution-ShareAlike 4.0 International License
% More info: https://bitbucket.org/ghorbanzade/umb-cs671-2015s
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Question 1}

Let $\mathcal{X}$, the set of examples, be the set of natural numbers.
The hypotheses space $H$ consists of all intervals of the form $[a,b]$ with $a \leq b$.
The concept that must be learned is an interval $[c,d]$, where all examples reside.

\begin{enumerate}[label=(\alph*)]
\item Let $h_1$, $h_2$ be two hypotheses.
What does it mean in this context that $h_1$ is more specific than $h_2$?
\item Design an algorithm that learns the target concept.
\end{enumerate}

\subsection*{Solution}

\begin{enumerate}[label=(\alph*)]
\item Since hypotheses space $H$ is the set of intervals of the form $[a, b]$ with $a \leq b$, let us present hypothesis $h_1$ and $h_2$ as intervals $[x_1, y_1]$ and $[x_2, y_2]$ respectively, where $x_1 \leq y_1$ and $x_2 \leq y_2$.

By definition, hypothesis $h_1$ is more specific than $h_2$ if for every concept (natural number) $i \in h_1$, $i \in h_2$ as well.
For this to happen, for any integer $i$ in the interval $[x_1, y_1]$ we should have $i \in [x_2, y_2]$.
Alternatively, $h_1$ is more specific than $h_2$ when $[x_1, y_1] \subseteq [x_2, y_2]$.

\item The objective is to propose an algorithm to find the consistent hypothesis (target concept) using both positive and negative examples.
To achieve this objective, we initialize most general hypothesis as the interval $[-\infty, \infty]$ and least general hypothesis as the empty set $\emptyset$.
For any concept $c$, consistent hypothesis can be updated using \textsc{Update-Concept} algorithm whose pseudo-code is given in Algorithm 1 and in which \textit{SB} and \textit{GB} are respectively maximally specific and maximally general positive hypothesis boundaries.

\begin{algorithm}[H]
\caption{\textsc{LearnExample($c$)}}\label{euclid}
\begin{algorithmic}[1]
\If {concept is positive}
\State add concept to SB
\For {$i \leftarrow 1$ to number of GB intervals}
\If {concept $\notin$ interval $i$}
\State remove interval $i$ from GB
\EndIf
\EndFor
\Else
\For {$i \leftarrow 1$ to number of GB intervals}
\If {concept $\in$ interval $i$}
\State remove concept from interval $i$
\Comment divides interval $i$ into two intervals
\EndIf
\EndFor
\EndIf
\end{algorithmic}
\end{algorithm}

\end{enumerate}
